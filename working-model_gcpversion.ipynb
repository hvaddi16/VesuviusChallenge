{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# from sklearn.model_selection import train_test_split\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# from sklearn.metrics import f1_score\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mio\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcloud\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m storage\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as notebook\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import f1_score\n",
    "import io\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu116\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp37-cp37m-linux_x86_64.whl (1978.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 GB\u001B[0m \u001B[31m500.8 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0:01\u001B[0m00:01\u001B[0mm\n",
      "\u001B[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torchvision-0.14.1%2Bcu116-cp37-cp37m-linux_x86_64.whl (24.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.2/24.2 MB\u001B[0m \u001B[31m22.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torchaudio-0.13.1%2Bcu116-cp37-cp37m-linux_x86_64.whl (4.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.2/4.2 MB\u001B[0m \u001B[31m16.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (1.26.15)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.13.1+cu116 torchaudio-0.13.1+cu116 torchvision-0.14.1+cu116\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Inititiation Block\n",
    "Z_START = 25\n",
    "Z_DIM = 10\n",
    "BUFFER = 30\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket('dlproject-7643')\n",
    "def get_img_bucket(text):\n",
    "    blob = bucket.blob(text)\n",
    "    img_bytes = io.BytesIO(blob.download_as_bytes())\n",
    "    img = Image.open(img_bytes)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T22:10:06.467255Z",
     "iopub.status.busy": "2023-04-18T22:10:06.466701Z",
     "iopub.status.idle": "2023-04-18T22:10:06.472962Z",
     "shell.execute_reply": "2023-04-18T22:10:06.471534Z",
     "shell.execute_reply.started": "2023-04-18T22:10:06.467204Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# gold = np.array(Image.open(\"/kaggle/input/vesuvius-challenge-ink-detection/train/3/inklabels.png\"))\n",
    "# mask=np.array(Image.open(\"/kaggle/input/vesuvius-challenge-ink-detection/train/3/mask.png\"))\n",
    "# gold2 = np.array(Image.open(\"/kaggle/input/vesuvius-challenge-ink-detection/train/1/inklabels.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T22:10:08.475683Z",
     "iopub.status.busy": "2023-04-18T22:10:08.475187Z",
     "iopub.status.idle": "2023-04-18T22:10:08.481300Z",
     "shell.execute_reply": "2023-04-18T22:10:08.480089Z",
     "shell.execute_reply.started": "2023-04-18T22:10:08.475637Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#visualizing output and gold label\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "# ax1.imshow(gold2, cmap='gray')\n",
    "# ax2.imshow(gold, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_img(x):\n",
    "    PREFIX = \"vesuvius-challenge-ink-detection/train/\"+x+\"/surface_volume/\"\n",
    "    # Use glob.glob to get a list of all the file paths\n",
    "    file_paths = [PREFIX + \"{:02d}.tif\".format(i) for i in range(0, Z_DIM)]\n",
    "\n",
    "    # Load the images into a list of numpy arrays\n",
    "    images = [np.array(get_img_bucket(filename), dtype=np.float32)/65535.0 for filename in notebook.tqdm(file_paths)]\n",
    "    data = np.array(images)\n",
    "    gold = np.array(get_img_bucket(\"vesuvius-challenge-ink-detection/train/\"+x+\"/inklabels.png\"))\n",
    "    mask=np.array(get_img_bucket(\"vesuvius-challenge-ink-detection/train/\"+x+\"/mask.png\"))\n",
    "    return data,gold,mask\n",
    "\n",
    "\n",
    "def pad_array(x,Buffer=BUFFER):\n",
    "    x=  np.pad(x, ((0, 0), (Buffer, Buffer), (Buffer, Buffer)), mode='constant', constant_values=0)\n",
    "    return x\n",
    "\n",
    "def get_pixels(mask,rect = [2500,3500,1500,2500]):\n",
    "    inside_rect = np.zeros(mask.shape, dtype=bool)\n",
    "    inside_rect[rect[0]:rect[1], rect[2]:rect[3]] = True\n",
    "\n",
    "    outside_rect = np.ones(mask.shape, dtype=bool)\n",
    "    outside_rect[rect[0]:rect[1], rect[2]:rect[3]] = True\n",
    "    \n",
    "    inside_rect = torch.from_numpy(np.pad(inside_rect,((BUFFER, BUFFER), (BUFFER, BUFFER)), mode='constant', constant_values=0)).float()\n",
    "    outside_rect = torch.from_numpy(np.pad(outside_rect,((BUFFER, BUFFER), (BUFFER, BUFFER)), mode='constant', constant_values=0)).float()\n",
    "    val_pixels = torch.argwhere(inside_rect)\n",
    "    train_pixels = torch.argwhere(outside_rect)\n",
    "    return train_pixels,val_pixels\n",
    "\n",
    "def pad_datasets(data,mask,gold):\n",
    "    mask = torch.from_numpy(np.pad(mask,((BUFFER, BUFFER), (BUFFER, BUFFER)), mode='constant', constant_values=0)).float()\n",
    "    gold = torch.from_numpy(np.pad(gold,((BUFFER, BUFFER), (BUFFER, BUFFER)), mode='constant', constant_values=0)).float()\n",
    "    data = pad_array(data)\n",
    "    data = torch.stack([torch.from_numpy(image) for image in data], dim=0)\n",
    "    return data,mask,gold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8481bac589e54f5d83e92d66c9703dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282ed4041daf412295f3cf3f4a95bd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 1627951760 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/var/tmp/ipykernel_13584/1205648212.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mgold\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload_img\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mtrain_pixels\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mval_pixels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_pixels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mgold\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpad_datasets\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mgold\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m     \u001B[0mt_pixels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_pixels\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mones\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_pixels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0mv_pixels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval_pixels\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mones\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval_pixels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/tmp/ipykernel_13584/3635437609.py\u001B[0m in \u001B[0;36mpad_datasets\u001B[0;34m(data, mask, gold)\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[0mgold\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgold\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBUFFER\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBUFFER\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mBUFFER\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBUFFER\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'constant'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconstant_values\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m     \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpad_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m     \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstack\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mimage\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mgold\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: [enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 1627951760 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "input_data ={}\n",
    "gold_labels ={}\n",
    "t_pixels = []\n",
    "v_pixels = []\n",
    "\n",
    "for i in [1,3]:\n",
    "    data,gold,mask = load_img(str(i))\n",
    "    train_pixels,val_pixels = get_pixels(mask)\n",
    "    data,mask,gold = pad_datasets(data,mask,gold)\n",
    "    t_pixels.append(torch.cat((train_pixels,i*torch.ones((train_pixels.shape[0],1))),dim=1).int())\n",
    "    v_pixels.append(torch.cat((val_pixels,i*torch.ones((val_pixels.shape[0],1))),dim=1).int())\n",
    "    gold_labels[i] = gold\n",
    "    input_data[i] = data\n",
    "    \n",
    "train_pixels = torch.cat(t_pixels,dim=0)\n",
    "val_pixels = torch.cat(v_pixels,dim=0)\n",
    "\n",
    "del t_pixels\n",
    "del v_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T22:12:07.954446Z",
     "iopub.status.busy": "2023-04-18T22:12:07.953263Z",
     "iopub.status.idle": "2023-04-18T22:12:07.965555Z",
     "shell.execute_reply": "2023-04-18T22:12:07.964181Z",
     "shell.execute_reply.started": "2023-04-18T22:12:07.954385Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SubvolumeDataset(Dataset):\n",
    "    def __init__(self, image_stack, label, pixels):\n",
    "        self.image_stack = image_stack\n",
    "        self.label = label\n",
    "        self.pixels = pixels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pixels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        y,x,key = self.pixels[index]\n",
    "        \n",
    "        try:\n",
    "            subvolume = self.image_stack[int(key.item())][:, y-BUFFER:y+BUFFER+1, x-BUFFER:x+BUFFER+1].view(1, Z_DIM, BUFFER*2+1, BUFFER*2+1)\n",
    "        except:\n",
    "            print(self.image_stack[key.item()][:, y-BUFFER:y+BUFFER+1, x-BUFFER:x+BUFFER+1].shape)\n",
    "            print(x,y,BUFFER)\n",
    "            subvolume = self.image_stack[key.item()][:, y-BUFFER:y+BUFFER+1, x-BUFFER:x+BUFFER+1].view(1, Z_DIM, BUFFER*2+1, BUFFER*2+1)\n",
    "        \n",
    "        inklabel = self.label[key.item()][y, x].view(1)\n",
    "        \n",
    "        return subvolume, inklabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-18T22:12:14.713168Z",
     "iopub.status.busy": "2023-04-18T22:12:14.711833Z",
     "iopub.status.idle": "2023-04-18T22:12:14.719480Z",
     "shell.execute_reply": "2023-04-18T22:12:14.718113Z",
     "shell.execute_reply.started": "2023-04-18T22:12:14.713111Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SubvolumeDataset(input_data,gold_labels,train_pixels)\n",
    "train_loader =  DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataset = SubvolumeDataset(input_data,gold_labels,val_pixels)\n",
    "val_loader =  DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T22:12:18.806656Z",
     "iopub.status.busy": "2023-04-18T22:12:18.806158Z",
     "iopub.status.idle": "2023-04-18T22:12:18.820445Z",
     "shell.execute_reply": "2023-04-18T22:12:18.818932Z",
     "shell.execute_reply.started": "2023-04-18T22:12:18.806609Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class InkDetection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels = 1,out_channels = 16, kernel_size = 3 , padding = 1)\n",
    "        self.act1 = nn.LeakyReLU()\n",
    "        \n",
    "        self.BN1 = nn.BatchNorm3d(16)\n",
    "        self.conv2 =  nn.Conv3d(in_channels = 16,  out_channels =32 ,kernel_size = 3, padding =1)\n",
    "        self.BN2 = nn.BatchNorm3d(32)\n",
    "        self.conv3 =  nn.Conv3d(in_channels = 32,  out_channels =64 ,kernel_size = 3, padding =1)\n",
    "        self.BN3 = nn.BatchNorm3d(64)\n",
    "        \n",
    "        self.pool = nn.MaxPool3d(2,2)\n",
    "        \n",
    "        self.ffn = nn.Sequential(nn.LazyLinear(128),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(128,128),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(128,2)\n",
    "        )\n",
    "        self.final = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X= self.conv1(X)\n",
    "        X= self.act1 (X)\n",
    "        X=self.BN1(X)\n",
    "        X=self.pool(X)\n",
    "        X= self.conv2(X)\n",
    "        X= self.act1 (X)\n",
    "        X=self.BN2(X)\n",
    "        X=self.pool(X)\n",
    "        X= self.conv3(X)\n",
    "        X= self.act1 (X)\n",
    "        X=self.BN3(X)\n",
    "        X=self.pool(X)\n",
    "\n",
    "        X=X.flatten(start_dim=1)\n",
    "\n",
    "        #linear layers\n",
    "        X=self.ffn(X)\n",
    "        X =self.final(X)\n",
    "\n",
    "\n",
    "        return X   \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-18T22:04:08.151290Z",
     "iopub.status.idle": "2023-04-18T22:04:08.151686Z",
     "shell.execute_reply": "2023-04-18T22:04:08.151509Z",
     "shell.execute_reply.started": "2023-04-18T22:04:08.151487Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #setting up the pretrained model\n",
    "# model = InkDetection().to(DEVICE)\n",
    "# # Loading the trained model weights\n",
    "# model.load_state_dict(torch.load('/kaggle/input/model-v2/model_PB.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T22:12:29.506066Z",
     "iopub.status.busy": "2023-04-18T22:12:29.504654Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f47ca7ed96a4166afec28654174bc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch Number:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22470e112cf949d4b719e4038187d841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch Number:   0%|          | 0/7813 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605215a93d3b48e098e6962d5cd80061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch Number:   0%|          | 0/311906 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "\n",
    "model = InkDetection().to(DEVICE)\n",
    "model.zero_grad()\n",
    "LEARNING_RATE = 0.0001\n",
    "TRAINING_STEPS = 30000\n",
    "class_weights = torch.Tensor([0.18,0.82]).to(DEVICE)\n",
    "f1_running= 0\n",
    "\n",
    "criterion = nn.BCELoss(weight=class_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "i=0\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "progress_bar_epoch = notebook.tqdm(range(num_epochs),desc = \"Epoch Number\",leave =True)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in progress_bar_epoch:\n",
    "    model.train()\n",
    "    f1_running= 0\n",
    "    train_loss = 0\n",
    "    accuracy = 0\n",
    "    progress_bar = notebook.tqdm(train_loader,desc = \"Batch Number\",leave =True)\n",
    "    #Training loop\n",
    "    for i,batch in enumerate(progress_bar):\n",
    "        optimizer.zero_grad()\n",
    "        X,y =batch\n",
    "\n",
    "        y_onehot = torch.nn.functional.one_hot(y.squeeze().long(),num_classes =2).float().to(DEVICE)\n",
    "        # print(y_onehot.shape)\n",
    "\n",
    "\n",
    "        output = model(X.to(DEVICE))\n",
    "\n",
    "        if i>TRAINING_STEPS:\n",
    "            break\n",
    "        loss = criterion(output, y_onehot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss = loss.clone().detach().item()\n",
    "\n",
    "        predicted=torch.argmax(output.clone().detach(),dim=1).unsqueeze(1)\n",
    "        # predicted=(predicted>0.4).type(torch.int)\n",
    "\n",
    "        epsilon = 1e-5\n",
    "\n",
    "\n",
    "        true_positives = torch.sum(torch.mul(predicted ,y)).float()\n",
    "        true_negatives = torch.sum(torch.mul((1-predicted ),(1-y))).float()\n",
    "        false_positives = torch.sum(torch.mul(predicted,(1-y))).float()\n",
    "        false_negatives = torch.sum(torch.mul((1-predicted), y)).float()\n",
    "        positives = true_positives + false_positives\n",
    "        negatives = true_negatives + false_negatives\n",
    "        accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives + epsilon)\n",
    "        precision = true_positives / (true_positives + false_positives + epsilon)\n",
    "        \n",
    "        recall = true_positives / (true_positives + false_negatives + epsilon)\n",
    "        \n",
    "        f1 = (1.25*precision*recall/(0.25*precision+recall+epsilon)).item()\n",
    "        f1_running += f1\n",
    "        if i%100 == 0:\n",
    "\n",
    "            progress_bar.set_postfix({\"Running Loss\":train_loss,\"Mean F-1 \":f1_running/(i+1) ,\"Batch_F1 \": f1,\"Accuracy \": accuracy.item() , \"Total Positives in Batch \":y.sum().item(),\"True Positives \":true_positives.item(), \"Predicted_sum\":predicted.sum().item()} )\n",
    "            \n",
    "    #Eval loop\n",
    "    print(\"Evaluation after epoch no\",i)\n",
    "    model.eval()\n",
    "    f1_running_eval= 0\n",
    "    tp_running=0\n",
    "    tn_running=0\n",
    "    fp_running=0\n",
    "    fn_running=0\n",
    "#     criterion = nn.BCELoss(weight=class_weights)\n",
    "    # out_img = torch.zeros_like(gold).float()\n",
    "    progress_bar_val = notebook.tqdm(val_loader,desc = \"Batch Number\",leave =True)\n",
    "    with torch.no_grad():\n",
    "        for k,batch in enumerate(progress_bar_val):\n",
    "            X,y =batch\n",
    "            output = model.forward(X.to(DEVICE))\n",
    "\n",
    "            # for l,value in enumerate(output):\n",
    "            #     out_img[tuple(val_pixels[k*BATCH_SIZE+l])] = torch.argmax(value)\n",
    "\n",
    "            y_onehot = torch.nn.functional.one_hot(y.squeeze().long(),num_classes =2).float().to(DEVICE)\n",
    "            loss_eval = criterion(output.to(DEVICE), y_onehot.to(DEVICE))\n",
    "            eval_loss = loss_eval.clone().detach().item()\n",
    "\n",
    "            predicted=output.clone().detach()\n",
    "            predicted=torch.argmax(output.clone().detach(),dim=1).unsqueeze(1)\n",
    "    #         predicted=(predicted>0.4).type(torch.int)\n",
    "\n",
    "            epsilon = 1e-5\n",
    "\n",
    "            true_positives = torch.sum(torch.mul(predicted ,y)).float()\n",
    "            true_negatives = torch.sum(torch.mul((1-predicted ),(1-y))).float()\n",
    "            false_positives = torch.sum(torch.mul(predicted,(1-y))).float()\n",
    "            false_negatives = torch.sum(torch.mul((1-predicted), y)).float()\n",
    "            positives = true_positives + false_positives\n",
    "            negatives = true_negatives + false_negatives\n",
    "            accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives + epsilon)\n",
    "            precision = true_positives / (true_positives + false_positives + epsilon)\n",
    "\n",
    "            recall = true_positives / (true_positives + false_negatives + epsilon)\n",
    "            f1_eval = (1.25*precision*recall/(0.25*precision+recall+epsilon)).item()\n",
    "            tp_running+=true_positives\n",
    "            tn_running+=true_negatives\n",
    "            fp_running+=false_positives\n",
    "            fn_running+=false_negatives\n",
    "            f1_running_eval = (1.25*tp_running/(1.25*tp_running+0.25*fn_running+fp_running+epsilon))\n",
    "            if i%100 == 0:\n",
    "                progress_bar_val.set_postfix({\"Running Loss\":eval_loss,\"Batch F-1 \":f1_eval ,\"Accuracy \": accuracy.item() , \"Total Positives in Batch \":y.sum().item(),\"True Positives \":true_positives.item(), \"Predicted_sum\":predicted.sum().item()} )\n",
    "                print(\"Evaluation after epoch no\",i,' : ',f1_running_eval.item())\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    progress_bar_epoch.set_postfix({\"Training Loss\": train_loss , \"Train F-1\": f1_running/(i+1)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-18T22:04:08.158217Z",
     "iopub.status.idle": "2023-04-18T22:04:08.158618Z",
     "shell.execute_reply": "2023-04-18T22:04:08.158441Z",
     "shell.execute_reply.started": "2023-04-18T22:04:08.158420Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Training...\")\n",
    "\n",
    "# # model = InkDetection().to(DEVICE)\n",
    "# model.zero_grad()\n",
    "# LEARNING_RATE = 0.001\n",
    "# TRAINING_STEPS = 30000\n",
    "# class_weights = torch.Tensor([0.18,0.82]).to(DEVICE)\n",
    "# f1_running= 0\n",
    "# model.train()\n",
    "# criterion = nn.BCELoss(weight=class_weights)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# i=0\n",
    "\n",
    "\n",
    "\n",
    "# num_epochs = 5\n",
    "\n",
    "# progress_bar_epoch = notebook.tqdm(range(num_epochs),desc = \"Epoch Number\",leave =True)\n",
    "\n",
    "\n",
    "# for epoch in progress_bar_epoch:\n",
    "#     f1_running= 0\n",
    "#     train_loss = 0\n",
    "#     accuracy = 0\n",
    "#     progress_bar = notebook.tqdm(train_loader,desc = \"Batch Number\",leave =True)\n",
    "#     for i,batch in enumerate(progress_bar):\n",
    "#         optimizer.zero_grad()\n",
    "#         X,y =batch\n",
    "\n",
    "#         y_onehot = torch.nn.functional.one_hot(y.squeeze().long(),num_classes =2).float().to(DEVICE)\n",
    "#         # print(y_onehot.shape)\n",
    "\n",
    "\n",
    "#         output = model(X.to(DEVICE))\n",
    "\n",
    "#         if i>TRAINING_STEPS:\n",
    "#             break\n",
    "#         loss = criterion(output, y_onehot)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         train_loss = loss.clone().detach().item()\n",
    "\n",
    "#         predicted=torch.argmax(output.clone().detach(),dim=1).unsqueeze(1)\n",
    "#         # predicted=(predicted>0.4).type(torch.int)\n",
    "\n",
    "#         epsilon = 1e-5\n",
    "\n",
    "\n",
    "#         true_positives = torch.sum(torch.mul(predicted ,y)).float()\n",
    "#         true_negatives = torch.sum(torch.mul((1-predicted ),(1-y))).float()\n",
    "#         false_positives = torch.sum(torch.mul(predicted,(1-y))).float()\n",
    "#         false_negatives = torch.sum(torch.mul((1-predicted), y)).float()\n",
    "#         positives = true_positives + false_positives\n",
    "#         negatives = true_negatives + false_negatives\n",
    "#         accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives + epsilon)\n",
    "#         precision = true_positives / (true_positives + false_positives + epsilon)\n",
    "        \n",
    "#         recall = true_positives / (true_positives + false_negatives + epsilon)\n",
    "        \n",
    "#         f1 = (1.25*precision*recall/(0.25*precision+recall+epsilon)).item()\n",
    "#         f1_running += f1\n",
    "#         if i%100 == 0:\n",
    "\n",
    "#             progress_bar.set_postfix({\"Running Loss\":train_loss,\"Mean F-1 \":f1_running/(i+1) ,\"Batch_F1 \": f1,\"Accuracy \": accuracy.item() , \"Total Positives in Batch \":y.sum().item(),\"True Positives \":true_positives.item(), \"Predicted_sum\":predicted.sum().item()} )\n",
    "\n",
    "\n",
    "#     progress_bar_epoch.set_postfix({\"Training Loss\": train_loss , \"Train F-1\": f1_running/(i+1)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-18T22:04:08.160061Z",
     "iopub.status.idle": "2023-04-18T22:04:08.160473Z",
     "shell.execute_reply": "2023-04-18T22:04:08.160297Z",
     "shell.execute_reply.started": "2023-04-18T22:04:08.160275Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_seq_1_and_3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-18T22:04:08.162553Z",
     "iopub.status.idle": "2023-04-18T22:04:08.162974Z",
     "shell.execute_reply": "2023-04-18T22:04:08.162794Z",
     "shell.execute_reply.started": "2023-04-18T22:04:08.162772Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_dataset = SubvolumeDataset(data,gold,val_pixels)\n",
    "val_loader =  DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-18T22:04:08.164554Z",
     "iopub.status.idle": "2023-04-18T22:04:08.164976Z",
     "shell.execute_reply": "2023-04-18T22:04:08.164794Z",
     "shell.execute_reply.started": "2023-04-18T22:04:08.164771Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = InkDetection().to(DEVICE)\n",
    "model.load_state_dict(torch.load('/kaggle/input/model-v2/model_PB.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-18T22:04:08.166583Z",
     "iopub.status.idle": "2023-04-18T22:04:08.167003Z",
     "shell.execute_reply": "2023-04-18T22:04:08.166825Z",
     "shell.execute_reply.started": "2023-04-18T22:04:08.166803Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-18T22:04:08.169242Z",
     "iopub.status.idle": "2023-04-18T22:04:08.169647Z",
     "shell.execute_reply": "2023-04-18T22:04:08.169468Z",
     "shell.execute_reply.started": "2023-04-18T22:04:08.169446Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "progress_bar = notebook.tqdm(val_loader,desc = \"Batch Number\",leave =True)\n",
    "class_weights = torch.Tensor([0.18,0.82]).to(DEVICE)\n",
    "f1_running= 0\n",
    "tp_running=0\n",
    "tn_running=0\n",
    "fp_running=0\n",
    "fn_running=0\n",
    "criterion = nn.BCELoss(weight=class_weights)\n",
    "out_img = torch.zeros_like(gold).float()\n",
    "with torch.no_grad():\n",
    "    for i,batch in enumerate(progress_bar):\n",
    "        X,y =batch\n",
    "        output = model.forward(X.to(DEVICE))\n",
    "    \n",
    "        for j,value in enumerate(output):\n",
    "            out_img[tuple(val_pixels[i*BATCH_SIZE+j])] = torch.argmax(value)\n",
    "            \n",
    "        y_onehot = torch.nn.functional.one_hot(y.squeeze().long(),num_classes =2).float().to(DEVICE)\n",
    "        loss = criterion(output.to(DEVICE), y_onehot.to(DEVICE))\n",
    "        train_loss = loss.clone().detach().item()\n",
    "\n",
    "        predicted=output.clone().detach()\n",
    "        predicted=torch.argmax(output.clone().detach(),dim=1).unsqueeze(1)\n",
    "#         predicted=(predicted>0.4).type(torch.int)\n",
    "\n",
    "        epsilon = 1e-5\n",
    "\n",
    "        true_positives = torch.sum(torch.mul(predicted ,y)).float()\n",
    "        true_negatives = torch.sum(torch.mul((1-predicted ),(1-y))).float()\n",
    "        false_positives = torch.sum(torch.mul(predicted,(1-y))).float()\n",
    "        false_negatives = torch.sum(torch.mul((1-predicted), y)).float()\n",
    "        positives = true_positives + false_positives\n",
    "        negatives = true_negatives + false_negatives\n",
    "        accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives + epsilon)\n",
    "        precision = true_positives / (true_positives + false_positives + epsilon)\n",
    "\n",
    "        recall = true_positives / (true_positives + false_negatives + epsilon)\n",
    "        f1 = (1.25*precision*recall/(0.25*precision+recall+epsilon)).item()\n",
    "        tp_running+=true_positives\n",
    "        tn_running+=true_negatives\n",
    "        fp_running+=false_positives\n",
    "        fn_running+=false_negatives\n",
    "        f1_running = (1.25*tp_running/(1.25*tp_running+0.25*fn_running+fp_running+epsilon))\n",
    "        if i%100 == 0:\n",
    "            progress_bar.set_postfix({\"Running Loss\":train_loss,\"Batch F-1 \":f1 ,\"Accuracy \": accuracy.item() , \"Total Positives in Batch \":y.sum().item(),\"True Positives \":true_positives.item(), \"Predicted_sum\":predicted.sum().item()} )\n",
    "            print(f1_running.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-18T22:04:08.171112Z",
     "iopub.status.idle": "2023-04-18T22:04:08.171482Z",
     "shell.execute_reply": "2023-04-18T22:04:08.171314Z",
     "shell.execute_reply.started": "2023-04-18T22:04:08.171295Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#visualizing output and gold label\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(out_img.cpu()[rect[0]:rect[1],rect[2]:rect[3]], cmap='gray')\n",
    "ax2.imshow(gold.cpu()[rect[0]:rect[1],rect[2]:rect[3]], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-18T22:04:08.173463Z",
     "iopub.status.idle": "2023-04-18T22:04:08.174072Z",
     "shell.execute_reply": "2023-04-18T22:04:08.173703Z",
     "shell.execute_reply.started": "2023-04-18T22:04:08.173679Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training...\")\n",
    "\n",
    "# model = InkDetection().to(DEVICE)\n",
    "model.zero_grad()\n",
    "LEARNING_RATE = 0.0001\n",
    "TRAINING_STEPS = 5000\n",
    "class_weights = torch.Tensor([0.18,0.82]).to(DEVICE)\n",
    "f1_running= 0\n",
    "\n",
    "criterion = nn.BCELoss(weight=class_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "i=0\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "progress_bar_epoch = notebook.tqdm(range(num_epochs),desc = \"Epoch Number\",leave =True)\n",
    "\n",
    "\n",
    "for epoch in progress_bar_epoch:\n",
    "    model.train()\n",
    "    f1_running= 0\n",
    "    train_loss = 0\n",
    "    accuracy = 0\n",
    "    progress_bar = notebook.tqdm(train_loader,desc = \"Batch Number\",leave =True)\n",
    "    #Training loop\n",
    "    for i,batch in enumerate(progress_bar):\n",
    "        optimizer.zero_grad()\n",
    "        X,y =batch\n",
    "\n",
    "        y_onehot = torch.nn.functional.one_hot(y.squeeze().long(),num_classes =2).float().to(DEVICE)\n",
    "        # print(y_onehot.shape)\n",
    "\n",
    "\n",
    "        output = model(X.to(DEVICE))\n",
    "\n",
    "        if i>TRAINING_STEPS:\n",
    "            break\n",
    "        loss = criterion(output, y_onehot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss = loss.clone().detach().item()\n",
    "\n",
    "        predicted=torch.argmax(output.clone().detach(),dim=1).unsqueeze(1)\n",
    "        # predicted=(predicted>0.4).type(torch.int)\n",
    "\n",
    "        epsilon = 1e-5\n",
    "\n",
    "\n",
    "        true_positives = torch.sum(torch.mul(predicted ,y)).float()\n",
    "        true_negatives = torch.sum(torch.mul((1-predicted ),(1-y))).float()\n",
    "        false_positives = torch.sum(torch.mul(predicted,(1-y))).float()\n",
    "        false_negatives = torch.sum(torch.mul((1-predicted), y)).float()\n",
    "        positives = true_positives + false_positives\n",
    "        negatives = true_negatives + false_negatives\n",
    "        accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives + epsilon)\n",
    "        precision = true_positives / (true_positives + false_positives + epsilon)\n",
    "        \n",
    "        recall = true_positives / (true_positives + false_negatives + epsilon)\n",
    "        \n",
    "        f1 = (1.25*precision*recall/(0.25*precision+recall+epsilon)).item()\n",
    "        f1_running += f1\n",
    "        if i%100 == 0:\n",
    "\n",
    "            progress_bar.set_postfix({\"Running Loss\":train_loss,\"Mean F-1 \":f1_running/(i+1) ,\"Batch_F1 \": f1,\"Accuracy \": accuracy.item() , \"Total Positives in Batch \":y.sum().item(),\"True Positives \":true_positives.item(), \"Predicted_sum\":predicted.sum().item()} )\n",
    "            \n",
    "    #Eval loop\n",
    "    print(\"Evaluation after epoch no\",i)\n",
    "    model.eval()\n",
    "    f1_running_eval= 0\n",
    "    tp_running=0\n",
    "    tn_running=0\n",
    "    fp_running=0\n",
    "    fn_running=0\n",
    "#     criterion = nn.BCELoss(weight=class_weights)\n",
    "    out_img = torch.zeros_like(gold).float()\n",
    "    with torch.no_grad():\n",
    "        for k,batch in enumerate(progress_bar_val):\n",
    "            X,y =batch\n",
    "            output = model.forward(X.to(DEVICE))\n",
    "\n",
    "            for l,value in enumerate(output):\n",
    "                out_img[tuple(val_pixels[k*BATCH_SIZE+l])] = torch.argmax(value)\n",
    "\n",
    "            y_onehot = torch.nn.functional.one_hot(y.squeeze().long(),num_classes =2).float().to(DEVICE)\n",
    "            loss_eval = criterion(output.to(DEVICE), y_onehot.to(DEVICE))\n",
    "            eval_loss = loss_eval.clone().detach().item()\n",
    "\n",
    "            predicted=output.clone().detach()\n",
    "            predicted=torch.argmax(output.clone().detach(),dim=1).unsqueeze(1)\n",
    "    #         predicted=(predicted>0.4).type(torch.int)\n",
    "\n",
    "            epsilon = 1e-5\n",
    "\n",
    "            true_positives = torch.sum(torch.mul(predicted ,y)).float()\n",
    "            true_negatives = torch.sum(torch.mul((1-predicted ),(1-y))).float()\n",
    "            false_positives = torch.sum(torch.mul(predicted,(1-y))).float()\n",
    "            false_negatives = torch.sum(torch.mul((1-predicted), y)).float()\n",
    "            positives = true_positives + false_positives\n",
    "            negatives = true_negatives + false_negatives\n",
    "            accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives + epsilon)\n",
    "            precision = true_positives / (true_positives + false_positives + epsilon)\n",
    "\n",
    "            recall = true_positives / (true_positives + false_negatives + epsilon)\n",
    "            f1_eval = (1.25*precision*recall/(0.25*precision+recall+epsilon)).item()\n",
    "            tp_running+=true_positives\n",
    "            tn_running+=true_negatives\n",
    "            fp_running+=false_positives\n",
    "            fn_running+=false_negatives\n",
    "            f1_running_eval = (1.25*tp_running/(1.25*tp_running+0.25*fn_running+fp_running+epsilon))\n",
    "            if i%100 == 0:\n",
    "                progress_bar_val.set_postfix({\"Running Loss\":eval_loss,\"Batch F-1 \":f1_eval ,\"Accuracy \": accuracy.item() , \"Total Positives in Batch \":y.sum().item(),\"True Positives \":true_positives.item(), \"Predicted_sum\":predicted.sum().item()} )\n",
    "                print(\"Evaluation after epoch no\",i,' : ',f1_running_eval.item())\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    progress_bar_epoch.set_postfix({\"Training Loss\": train_loss , \"Train F-1\": f1_running/(i+1)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-18T22:04:08.176309Z",
     "iopub.status.idle": "2023-04-18T22:04:08.176755Z",
     "shell.execute_reply": "2023-04-18T22:04:08.176530Z",
     "shell.execute_reply.started": "2023-04-18T22:04:08.176509Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "progress_bar_val = notebook.tqdm(val_loader,desc = \"Batch Number\",leave =True)\n",
    "class_weights = torch.Tensor([0.18,0.82]).to(DEVICE)\n",
    "model.eval()\n",
    "f1_running= 0\n",
    "tp_running=0\n",
    "tn_running=0\n",
    "fp_running=0\n",
    "fn_running=0\n",
    "criterion = nn.BCELoss(weight=class_weights)\n",
    "out_img = torch.zeros_like(gold).float()\n",
    "with torch.no_grad():\n",
    "    for k,batch in enumerate(progress_bar_val):\n",
    "        X,y =batch\n",
    "        output = model.forward(X.to(DEVICE))\n",
    "    \n",
    "        for l,value in enumerate(output):\n",
    "            out_img[tuple(val_pixels[k*BATCH_SIZE+l])] = torch.argmax(value)\n",
    "            \n",
    "        y_onehot = torch.nn.functional.one_hot(y.squeeze().long(),num_classes =2).float().to(DEVICE)\n",
    "        loss_eval = criterion(output.to(DEVICE), y_onehot.to(DEVICE))\n",
    "        train_loss = loss_eval.clone().detach().item()\n",
    "\n",
    "        predicted=output.clone().detach()\n",
    "        predicted=torch.argmax(output.clone().detach(),dim=1).unsqueeze(1)\n",
    "#         predicted=(predicted>0.4).type(torch.int)\n",
    "\n",
    "        epsilon = 1e-5\n",
    "\n",
    "        true_positives = torch.sum(torch.mul(predicted ,y)).float()\n",
    "        true_negatives = torch.sum(torch.mul((1-predicted ),(1-y))).float()\n",
    "        false_positives = torch.sum(torch.mul(predicted,(1-y))).float()\n",
    "        false_negatives = torch.sum(torch.mul((1-predicted), y)).float()\n",
    "        positives = true_positives + false_positives\n",
    "        negatives = true_negatives + false_negatives\n",
    "        accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives + epsilon)\n",
    "        precision = true_positives / (true_positives + false_positives + epsilon)\n",
    "\n",
    "        recall = true_positives / (true_positives + false_negatives + epsilon)\n",
    "        f1 = (1.25*precision*recall/(0.25*precision+recall+epsilon)).item()\n",
    "        tp_running+=true_positives\n",
    "        tn_running+=true_negatives\n",
    "        fp_running+=false_positives\n",
    "        fn_running+=false_negatives\n",
    "        f1_running = (1.25*tp_running/(1.25*tp_running+0.25*fn_running+fp_running+epsilon))\n",
    "        if i%100 == 0:\n",
    "            progress_bar_val.set_postfix({\"Running Loss\":train_loss,\"Batch F-1 \":f1 ,\"Accuracy \": accuracy.item() , \"Total Positives in Batch \":y.sum().item(),\"True Positives \":true_positives.item(), \"Predicted_sum\":predicted.sum().item()} )\n",
    "            print(f1_running.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# rect = [1500,2500,3500,4500]\n",
    "# rect=[4500,5500,2000,3000]\n",
    "# rect=[7200,8300,1500,2500]\n",
    "# rect = [2500,3500,1500,2500]\n",
    "# inside_rect = np.zeros(mask.shape, dtype=bool)\n",
    "# inside_rect[rect[0]:rect[1], rect[2]:rect[3]] = True\n",
    "\n",
    "# outside_rect = np.ones(mask.shape, dtype=bool)\n",
    "# outside_rect[rect[0]:rect[1], rect[2]:rect[3]] = True\n",
    "# data = pad_array(data)\n",
    "# mask = torch.from_numpy(np.pad(mask,((BUFFER, BUFFER), (BUFFER, BUFFER)), mode='constant', constant_values=0)).float().to(DEVICE)\n",
    "# gold = torch.from_numpy(np.pad(gold,((BUFFER, BUFFER), (BUFFER, BUFFER)), mode='constant', constant_values=0)).float().to(DEVICE)\n",
    "# data = torch.stack([torch.from_numpy(image) for image in data], dim=0).to(DEVICE)\n",
    "\n",
    "# inside_rect = torch.from_numpy(np.pad(inside_rect,((BUFFER, BUFFER), (BUFFER, BUFFER)), mode='constant', constant_values=0)).float().to(DEVICE)\n",
    "# outside_rect = torch.from_numpy(np.pad(outside_rect,((BUFFER, BUFFER), (BUFFER, BUFFER)), mode='constant', constant_values=0)).float().to(DEVICE)\n",
    "# val_pixels = torch.argwhere(inside_rect)\n",
    "# train_pixels = torch.argwhere(outside_rect)\n",
    "\n",
    "### Balancing Datasets\n",
    "# train_pixels, val_pixels = train_test_split(pixels, test_size=0.2)\n",
    "# train_dataset = SubvolumeDataset(data,gold,train_pixels)\n",
    "# train_loader =  DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_dataset = SubvolumeDataset(data,gold,val_pixels)\n",
    "# val_loader =  DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m107"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}