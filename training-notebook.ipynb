{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:59:46.054112Z","iopub.execute_input":"2023-05-02T21:59:46.054387Z","iopub.status.idle":"2023-05-02T21:59:46.149901Z","shell.execute_reply.started":"2023-05-02T21:59:46.054362Z","shell.execute_reply":"2023-05-02T21:59:46.148986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %pip install deepspeed","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:30:59.609707Z","iopub.execute_input":"2023-05-02T16:30:59.610597Z","iopub.status.idle":"2023-05-02T16:30:59.615033Z","shell.execute_reply.started":"2023-05-02T16:30:59.610564Z","shell.execute_reply":"2023-05-02T16:30:59.614175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree(\"/kaggle/working/lightning_logs\")","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:30:59.616693Z","iopub.execute_input":"2023-05-02T16:30:59.617367Z","iopub.status.idle":"2023-05-02T16:30:59.623936Z","shell.execute_reply.started":"2023-05-02T16:30:59.617335Z","shell.execute_reply":"2023-05-02T16:30:59.623159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pytorch_lightning as lt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport tqdm.notebook as notebook\nfrom torch.utils.data import Dataset, DataLoader\nimport PIL.Image as Image\nimport io\nimport gc\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint,StochasticWeightAveraging\nfrom torchmetrics.classification import BinaryFBetaScore as Fbeta\n# import deepspeed","metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:59:46.151897Z","iopub.execute_input":"2023-05-02T21:59:46.152442Z","iopub.status.idle":"2023-05-02T22:00:00.564614Z","shell.execute_reply.started":"2023-05-02T21:59:46.152410Z","shell.execute_reply":"2023-05-02T22:00:00.563635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-05-02T22:00:00.565907Z","iopub.execute_input":"2023-05-02T22:00:00.566241Z","iopub.status.idle":"2023-05-02T22:00:00.579289Z","shell.execute_reply.started":"2023-05-02T22:00:00.566207Z","shell.execute_reply":"2023-05-02T22:00:00.578371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inititiation Block\nZ_START = 25\nZ_DIM = 10\nBUFFER = 30\nBATCH_SIZE = 128","metadata":{"execution":{"iopub.status.busy":"2023-05-02T22:00:00.582024Z","iopub.execute_input":"2023-05-02T22:00:00.582403Z","iopub.status.idle":"2023-05-02T22:00:00.587766Z","shell.execute_reply.started":"2023-05-02T22:00:00.582376Z","shell.execute_reply":"2023-05-02T22:00:00.585521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# client = storage.Client()\n# bucket = client.get_bucket('dlproject-7643')\n# /kaggle/input/vesuvius-challenge-ink-detection/train\ndef get_img_bucket(text):\n#     blob = bucket.blob(text)\n#     img_bytes = io.BytesIO(blob.download_as_bytes())\n    img = Image.open(text)\n    return img\n\ndef load_img(x):\n    PREFIX = \"/kaggle/input/vesuvius-challenge-ink-detection/train/\"+x+\"/surface_volume/\"\n    # Use glob.glob to get a list of all the file paths\n    file_paths = [PREFIX + \"{:02d}.tif\".format(i) for i in range(Z_START, Z_START + Z_DIM)]\n\n    # Load the images into a list of numpy arrays\n    images = [np.array(get_img_bucket(filename), dtype=np.float32)/65535.0 for filename in notebook.tqdm(file_paths)]\n    data = np.array(images)\n    gold = np.array(get_img_bucket(\"/kaggle/input/vesuvius-challenge-ink-detection/train/\"+x+\"/inklabels.png\"))\n    mask=np.array(get_img_bucket(\"/kaggle/input/vesuvius-challenge-ink-detection/train/\"+x+\"/mask.png\"))\n    return data,gold,mask\n\ndef pad_array(x,Buffer=BUFFER):\n    x=  np.pad(x, ((0, 0), (Buffer, Buffer), (Buffer, Buffer)), mode='constant', constant_values=0)\n    return x\n\ndef get_pixels(mask,rect = [2500,3500,1500,2500]):\n    inside_rect = np.zeros(mask.shape, dtype=bool)\n    inside_rect[rect[0]:rect[1], rect[2]:rect[3]] = True\n\n    outside_rect = np.ones(mask.shape, dtype=bool)\n    outside_rect[rect[0]:rect[1], rect[2]:rect[3]] = False\n    \n    inside_rect = torch.from_numpy(np.pad(inside_rect,((BUFFER, BUFFER), (BUFFER, BUFFER)), mode='constant', constant_values=0)).float()\n    outside_rect = torch.from_numpy(np.pad(outside_rect,((BUFFER, BUFFER), (BUFFER, BUFFER)), mode='constant', constant_values=0)).float()\n    val_pixels = torch.argwhere(inside_rect)\n    train_pixels = torch.argwhere(outside_rect)\n    return train_pixels,val_pixels\n\ndef pad_datasets(data,mask,gold):\n    mask = torch.from_numpy(np.pad(mask,((BUFFER, BUFFER), (BUFFER, BUFFER)), mode='constant', constant_values=0)).float()\n    gold = torch.from_numpy(np.pad(gold,((BUFFER, BUFFER), (BUFFER, BUFFER)), mode='constant', constant_values=0)).float()\n    data = pad_array(data)\n    data = torch.stack([torch.from_numpy(image) for image in data], dim=0)\n    return data,mask,gold","metadata":{"execution":{"iopub.status.busy":"2023-05-02T22:00:00.589169Z","iopub.execute_input":"2023-05-02T22:00:00.589599Z","iopub.status.idle":"2023-05-02T22:00:00.603517Z","shell.execute_reply.started":"2023-05-02T22:00:00.589570Z","shell.execute_reply":"2023-05-02T22:00:00.602384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_data ={}\ngold_labels ={}\nt_pixels = []\nv_pixels = []\n\nfor i in [1,3]:\n    data,gold,mask = load_img(str(i))\n    train_pixels,val_pixels = get_pixels(mask)\n    data,mask,gold = pad_datasets(data,mask,gold)\n    t_pixels.append(torch.cat((train_pixels,i*torch.ones((train_pixels.shape[0],1))),dim=1).int())\n    v_pixels.append(torch.cat((val_pixels,i*torch.ones((val_pixels.shape[0],1))),dim=1).int())\n    gold_labels[i] = gold\n    input_data[i] = data\n\n    del data\n    del gold\n\n    gc.collect()\n    \ntrain_pixels = torch.cat(t_pixels,dim=0)\nval_pixels = torch.cat(v_pixels,dim=0)\n\ndel t_pixels\ndel v_pixels\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:31:13.520281Z","iopub.execute_input":"2023-05-02T16:31:13.520621Z","iopub.status.idle":"2023-05-02T16:31:56.942901Z","shell.execute_reply.started":"2023-05-02T16:31:13.520592Z","shell.execute_reply":"2023-05-02T16:31:56.942041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SubvolumeDataset(Dataset):\n    def __init__(self, image_stack, label, pixels):\n        self.image_stack = image_stack\n        self.label = label\n        self.pixels = pixels\n\n    def __len__(self):\n        return len(self.pixels)\n    \n    def __getitem__(self, index):\n        y,x,key = self.pixels[index]\n        \n        try:\n            subvolume = self.image_stack[int(key.item())][:, y-BUFFER:y+BUFFER+1, x-BUFFER:x+BUFFER+1].view(1, Z_DIM, BUFFER*2+1, BUFFER*2+1)\n        except:\n            print(self.image_stack[key.item()][:, y-BUFFER:y+BUFFER+1, x-BUFFER:x+BUFFER+1].shape)\n            print(x,y,BUFFER)\n            subvolume = self.image_stack[key.item()][:, y-BUFFER:y+BUFFER+1, x-BUFFER:x+BUFFER+1].view(1, Z_DIM, BUFFER*2+1, BUFFER*2+1)\n        \n        inklabel = self.label[key.item()][y, x].view(1)\n        \n        return subvolume, inklabel","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:31:56.944287Z","iopub.execute_input":"2023-05-02T16:31:56.944612Z","iopub.status.idle":"2023-05-02T16:31:56.953654Z","shell.execute_reply.started":"2023-05-02T16:31:56.944581Z","shell.execute_reply":"2023-05-02T16:31:56.952655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = SubvolumeDataset(input_data,gold_labels,train_pixels)\ntrain_loader =  DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_dataset = SubvolumeDataset(input_data,gold_labels,val_pixels)\nval_loader =  DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:31:56.957227Z","iopub.execute_input":"2023-05-02T16:31:56.957558Z","iopub.status.idle":"2023-05-02T16:31:56.968084Z","shell.execute_reply.started":"2023-05-02T16:31:56.957526Z","shell.execute_reply":"2023-05-02T16:31:56.967157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Litmodel(lt.LightningModule):\n    def __init__(self,model,**kwargs):\n        super().__init__(**kwargs)\n        self.model = model\n        self.save_hyperparameters()\n    \n    def training_step(self,batch,batch_idx):\n        x,y = batch\n\n        z = self.model.forward(x.to(DEVICE))\n#         print(z.shape)\n\n        y = F.one_hot(y.squeeze().long(),num_classes = 2).float().to(DEVICE)\n        loss = F.binary_cross_entropy_with_logits(z,y)\n        self.log(\"batch_idx\",batch_idx)\n        return loss\n    \n#     def validation_step(self,batch,batch_idx):\n#         x,y = batch\n\n#         z = self.model.forward(x.to(DEVICE))\n#         y = F.one_hot(y.squeeze().long(),num_classes = 2).float().to(DEVICE)\n#         loss = F.binary_cross_entropy_with_logits(z,y)\n# #         f05 = Fbeta(num_classes =2,beta=0.5).to(DEVICE)\n# #         score = f05(z,y).to(DEVICE)\n#         self.log('val_loss', loss)\n# #         self.log(\"F0.5 score\",score)\n#         return loss\n\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(),lr = 1e-4)\n        return optimizer\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:42:07.355909Z","iopub.execute_input":"2023-05-02T16:42:07.356282Z","iopub.status.idle":"2023-05-02T16:42:07.364681Z","shell.execute_reply.started":"2023-05-02T16:42:07.356252Z","shell.execute_reply":"2023-05-02T16:42:07.363191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class InkDetection(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.conv1 = nn.Conv3d(in_channels = 1,out_channels = 16, kernel_size = 3 , padding = 1)\n        self.act1 = nn.LeakyReLU()\n        \n        self.BN1 = nn.BatchNorm3d(16)\n        self.conv2 =  nn.Conv3d(in_channels = 16,  out_channels =32 ,kernel_size = 3, padding =1)\n        self.BN2 = nn.BatchNorm3d(32)\n        self.conv3 =  nn.Conv3d(in_channels = 32,  out_channels =64 ,kernel_size = 3, padding =1)\n        self.BN3 = nn.BatchNorm3d(64)\n        \n        self.pool = nn.MaxPool3d(2,2)\n        \n        self.ffn = nn.Sequential(nn.LazyLinear(128),\n                                 nn.ReLU(),\n                                 nn.Dropout(0.2),\n                                 nn.Linear(128,128),\n                                 nn.ReLU(),\n                                 nn.Dropout(0.2),\n                                 nn.Linear(128,2)\n        )\n        self.final = nn.Sigmoid()\n        \n    def forward(self,X):\n        \n        X= self.conv1(X)\n        X= self.act1 (X)\n        X=self.BN1(X)\n        X=self.pool(X)\n        X= self.conv2(X)\n        X= self.act1 (X)\n        X=self.BN2(X)\n        X=self.pool(X)\n        X= self.conv3(X)\n        X= self.act1 (X)\n        X=self.BN3(X)\n        X=self.pool(X)\n\n        X=X.flatten(start_dim=1)\n\n        #linear layers\n        X=self.ffn(X)\n#         X =self.final(X)\n\n\n        return X   ","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:31:56.981993Z","iopub.execute_input":"2023-05-02T16:31:56.982316Z","iopub.status.idle":"2023-05-02T16:31:56.993216Z","shell.execute_reply.started":"2023-05-02T16:31:56.982293Z","shell.execute_reply":"2023-05-02T16:31:56.992311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(model,\"model.pt\")\n# torch.save(model.state_dict(),\"model_weights.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:31:56.996434Z","iopub.execute_input":"2023-05-02T16:31:56.996700Z","iopub.status.idle":"2023-05-02T16:31:57.006687Z","shell.execute_reply.started":"2023-05-02T16:31:56.996677Z","shell.execute_reply":"2023-05-02T16:31:57.005774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyEarlyStopping(EarlyStopping):\n    def on_validation_end(self,trainer,pl_module):\n        pass\n    def on_train_batch_start(batch,batch_idx):\n        if batch_idx>=10000:\n            return -1","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:31:57.007991Z","iopub.execute_input":"2023-05-02T16:31:57.009087Z","iopub.status.idle":"2023-05-02T16:31:57.017251Z","shell.execute_reply.started":"2023-05-02T16:31:57.009052Z","shell.execute_reply":"2023-05-02T16:31:57.016369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(\"/kaggle/working/lightning_logs/version_0/checkpoints\")","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:42:58.176452Z","iopub.execute_input":"2023-05-02T16:42:58.177033Z","iopub.status.idle":"2023-05-02T16:42:58.189927Z","shell.execute_reply.started":"2023-05-02T16:42:58.176993Z","shell.execute_reply":"2023-05-02T16:42:58.189053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping =  MyEarlyStopping(monitor = \"val_loss\",mode=\"min\" )\nlt_model = Litmodel(InkDetection())\n#trainer = lt.Trainer(strategy=\"auto\", accelerator=\"gpu\", devices=1, precision=16, limit_train_batches = 10000, max_epochs =5 ,accumulate_grad_batches = 10,resume_from_checkpoint = \"give checkpoint here\" )","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:42:11.220108Z","iopub.execute_input":"2023-05-02T16:42:11.220481Z","iopub.status.idle":"2023-05-02T16:42:11.234170Z","shell.execute_reply.started":"2023-05-02T16:42:11.220453Z","shell.execute_reply":"2023-05-02T16:42:11.233096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainer.fit(model=lt_model, train_dataloaders=train_loader)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:31:57.061464Z","iopub.execute_input":"2023-05-02T16:31:57.062168Z","iopub.status.idle":"2023-05-02T16:31:57.066393Z","shell.execute_reply.started":"2023-05-02T16:31:57.062134Z","shell.execute_reply":"2023-05-02T16:31:57.065434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load(\"/kaggle/working/lightning_logs/version_0/checkpoints/epoch=4-step=5000.ckpt\")\ncheckpoint[\"state_dict\"] = {key[6:]:value for key,value in checkpoint[\"state_dict\"].items()}\ntrained_model =  InkDetection()\ntrained_model.load_state_dict(checkpoint[\"state_dict\"])","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:47:00.645684Z","iopub.execute_input":"2023-05-02T16:47:00.646328Z","iopub.status.idle":"2023-05-02T16:47:00.681503Z","shell.execute_reply.started":"2023-05-02T16:47:00.646291Z","shell.execute_reply":"2023-05-02T16:47:00.677296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"progress_bar_val = notebook.tqdm(val_loader,desc = \"Batch Number\",leave =True)\ntrained_model.eval()\ntrained_model.to(DEVICE)\nf1_running= 0\ntp_running=0\ntn_running=0\nfp_running=0\nfn_running=0\n# out_img = torch.zeros_like(gold).float()\nwith torch.no_grad():\n    for k,batch in enumerate(progress_bar_val):\n        X,y =batch\n        output = trained_model.forward(X.to(DEVICE))\n    \n#         for l,value in enumerate(output):\n#             out_img[tuple(val_pixels[k*BATCH_SIZE+l])[:-1]] = torch.argmax(value)\n\n        predicted=output.clone().detach()\n        predicted=torch.argmax(output.clone().detach(),dim=1).unsqueeze(1)\n        y = y.to(DEVICE)\n        epsilon = 1e-5\n\n        true_positives = torch.sum(torch.mul(predicted ,y)).float()\n        true_negatives = torch.sum(torch.mul((1-predicted ),(1-y))).float()\n        false_positives = torch.sum(torch.mul(predicted,(1-y))).float()\n        false_negatives = torch.sum(torch.mul((1-predicted), y)).float()\n        positives = true_positives + false_positives\n        negatives = true_negatives + false_negatives\n        accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives + epsilon)\n        precision = true_positives / (true_positives + false_positives + epsilon)\n\n        recall = true_positives / (true_positives + false_negatives + epsilon)\n        f1 = (1.25*precision*recall/(0.25*precision+recall+epsilon)).item()\n        tp_running+=true_positives\n        tn_running+=true_negatives\n        fp_running+=false_positives\n        fn_running+=false_negatives\n        f1_running = (1.25*tp_running/(1.25*tp_running+0.25*fn_running+fp_running+epsilon))\n        if k%100 == 0:\n            progress_bar_val.set_postfix({\"Batch F-1 \":f1 ,\"Accuracy \": accuracy.item() , \"Total Positives in Batch \":y.sum().item(),\"True Positives \":true_positives.item(), \"Predicted_sum\":predicted.sum().item()} )\n            print(f1_running.item())\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-02T16:58:45.312910Z","iopub.execute_input":"2023-05-02T16:58:45.313293Z","iopub.status.idle":"2023-05-02T17:08:03.321566Z","shell.execute_reply.started":"2023-05-02T16:58:45.313263Z","shell.execute_reply":"2023-05-02T17:08:03.320465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"simonsZip\", \"zip\", \"/kaggle/working/lightning_logs\")","metadata":{"execution":{"iopub.status.busy":"2023-05-02T17:12:29.644438Z","iopub.execute_input":"2023-05-02T17:12:29.644860Z","iopub.status.idle":"2023-05-02T17:12:29.977889Z","shell.execute_reply.started":"2023-05-02T17:12:29.644823Z","shell.execute_reply":"2023-05-02T17:12:29.977013Z"},"trusted":true},"execution_count":null,"outputs":[]}]}